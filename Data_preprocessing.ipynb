{"cells":[{"cell_type":"markdown","source":["#Overview"],"metadata":{"id":"4Wyr6fl6JqkN"}},{"cell_type":"markdown","source":["This script performs preprocessing and tokenization of Yoruba phrases and their English literal translations from a CSV file. The goal is to clean the data, preserve important diacritics, remove noise (like HTML tags and extra spaces), and extract tokens (words) to prepare the dataset for translation modeling."],"metadata":{"id":"32E_Yni3Jyax"}},{"cell_type":"markdown","source":["The input is a CSV file\"yoruba_phrases.csv\" containing the following columns:\n","\n","Phrase: Yoruba proverbs.\n","\n","Literal Translation: Word-for-word English translation of the proverbs.\n","\n","Actual Meaning: Intended meaning of the proverb.\n","\n","The output is a cleaned and tokenized CSV file \"yoruba_phrases_processesed.csv\" that includes:\n","\n","Phrase: Cleaned Yoruba phrase.\n","\n","Literal Translation: Cleaned literal English translation.\n","\n","Phrase_Tokens: Yoruba phrase\n","\n","Literal_Translation_Tokens:Literal translation word tokens."],"metadata":{"id":"tLa2WRXwKI2s"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VBdC1hY2QApZ"},"outputs":[],"source":["# Import libraries\n","import pandas as pd\n","import unicodedata\n","import re"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rbuk_bp5QH_M"},"outputs":[],"source":["# Loading the dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Project 2 Context Matters/yoruba_phrases.csv\")"]},{"cell_type":"markdown","source":["#Preprocessing"],"metadata":{"id":"tyxOvCt9HzTk"}},{"cell_type":"markdown","source":["The normalize_and_clean function normalizes Unicode characters to NFC(Normalization Form Composed) form to ensure consistent representation of accented characters (e.g., ẹ, ò), removes any HTML tags using regular expressions, filters out unwanted characters by retaining only word characters (a–z, A–Z, 0–9, _), whitespaces, Yoruba diacritics (À–ỹ, à–ỹ), and apostrophes ('), and finally cleans up extra whitespace by converting multiple spaces into a single space and trimming any leading or trailing spaces."],"metadata":{"id":"o71Opx-YMWLE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y2NwH2gsQNPZ"},"outputs":[],"source":["# Define a function to normalize and clean text\n","def normalize_and_clean(text):\n","    text = unicodedata.normalize(\"NFC\", str(text))    # Normalize Unicode text\n","    text = re.sub(r\"<.*?>\", \"\", text)                 # Remove HTML tags\n","    text = re.sub(r\"[^\\w\\sÀ-ỹà-ỹ']\", \"\", text)        # Keep Yoruba diacritics\n","    text = re.sub(r\"\\s+\", \" \", text).strip()          # Remove extra whitespaces\n","    text = text.lower()                               # Convert all characters to lowercase\n","\n","    return text\n","\n","# Applying the cleaning function\n","df[\"Phrase\"] = df[\"Phrase\"].apply(normalize_and_clean)\n","df[\"Literal Translation\"] = df[\"Literal Translation\"].apply(normalize_and_clean)\n","df[\"Actual Meaning\"] = df[\"Actual Meaning\"].apply(normalize_and_clean)"]},{"cell_type":"code","source":["# Removing columns not needed in building the model\n","df.drop(['Actual Meaning'], axis=1, inplace=True)"],"metadata":{"id":"XhbnSJSLbdP4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Tokenization"],"metadata":{"id":"j0SHEp1CH49m"}},{"cell_type":"markdown","source":["The simple_tokenizer function uses regular expression (re) to identify and extract words from the text by matching sequences of alphanumeric characters and underscores (\\w+) that are bounded by word boundaries (\\b)."],"metadata":{"id":"pl3CfP3nIr7F"}},{"cell_type":"code","source":["# Define a simple tokenizer function to perform word tokenization\n","def simple_tokenizer(text):\n","    return re.findall(r'\\b\\w+\\b', str(text))       # Tokenize on word boundaries without altering the text"],"metadata":{"id":"CCNUXSvIEC4i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Applying the tokenizer\n","df['Phrase_Tokens'] = df['Phrase'].apply(simple_tokenizer)\n","df['Literal_Translation_Tokens'] = df['Literal Translation'].apply(simple_tokenizer)"],"metadata":{"id":"kF2iceZaEsE-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ckk76dFtQyZr","collapsed":true},"outputs":[],"source":["# Save the processed dataframe into a new CSV file\n","df.to_csv('/content/drive/MyDrive/Colab Notebooks/Project 2 Context Matters/yoruba_phrases_processesed.csv', index=False)"]},{"cell_type":"code","source":[],"metadata":{"id":"sIDZphxh7HiA"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1FwUsifkjOxVuhGrsH3UN9aJJGXvdPoUI","authorship_tag":"ABX9TyN+Tx5/y+YtFzuaH1vWmu6m"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}